import streamlit as st
import os
import torch
import torch.nn as nn
from torchvision import transforms
from torchvision.models import vit_b_16, ViT_B_16_Weights
from PIL import Image
import numpy as np
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
import base64
import time

# ================== THIáº¾T Láº¬P TRANG ==================
st.set_page_config(
    page_title="ğŸŒ¿ TrÃ­ Tuá»‡ NhÃ¢n Táº¡o NÃ´ng Nghiá»‡p",
    page_icon="ğŸŒ±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ================== CSS TÃ™Y CHá»ˆNH ==================
def add_custom_css():
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap');

    .main {
        padding: 0rem 1rem;
    }

    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        font-family: 'Poppins', sans-serif;
    }

    .main-header {
        background: linear-gradient(90deg, #00C851, #00695C);
        padding: 2rem;
        border-radius: 20px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        animation: slideDown 1s ease-out;
    }

    .main-header h1 {
        color: white;
        font-size: 3rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }

    .main-header p {
        color: #E8F5E8;
        font-size: 1.2rem;
        margin: 0.5rem 0 0 0;
        font-weight: 300;
    }

    .feature-card {
        background: rgba(255, 255, 255, 0.95);
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        margin: 1rem 0;
        border-left: 5px solid #4CAF50;
        transition: all 0.3s ease;
        animation: fadeInUp 0.8s ease-out;
    }

    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 35px rgba(0,0,0,0.2);
    }

    .upload-section {
        background: linear-gradient(45deg, #E8F5E8, #F1F8E9);
        padding: 2rem;
        border-radius: 15px;
        border: 2px dashed #4CAF50;
        text-align: center;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }

    .upload-section:hover {
        border-color: #2E7D32;
        background: linear-gradient(45deg, #C8E6C9, #DCEDC8);
    }

    .chat-container {
        background: white;
        border-radius: 15px;
        padding: 1rem;
        height: 400px;
        overflow-y: auto;
        box-shadow: inset 0 2px 10px rgba(0,0,0,0.1);
        margin: 1rem 0;
    }

    .user-message {
        background: linear-gradient(45deg, #2196F3, #21CBF3);
        color: white;
        padding: 1rem;
        border-radius: 20px 20px 5px 20px;
        margin: 0.5rem 0;
        max-width: 80%;
        margin-left: auto;
        display: block;
        animation: slideInRight 0.5s ease-out;
    }

    .bot-message {
        background: linear-gradient(45deg, #4CAF50, #8BC34A);
        color: white;
        padding: 1rem;
        border-radius: 20px 20px 20px 5px;
        margin: 0.5rem 0;
        max-width: 80%;
        animation: slideInLeft 0.5s ease-out;
    }

    .sidebar .stSelectbox > div > div {
        background: linear-gradient(45deg, #E8F5E8, #F1F8E9);
        border-radius: 10px;
    }

    .stButton > button {
        background: linear-gradient(45deg, #4CAF50, #45a049);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.3);
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(76, 175, 80, 0.4);
        background: linear-gradient(45deg, #45a049, #4CAF50);
    }

    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        text-align: center;
        margin: 0.5rem;
        box-shadow: 0 8px 25px rgba(0,0,0,0.2);
        transition: all 0.3s ease;
    }

    .metric-card:hover {
        transform: scale(1.05);
    }

    @keyframes fadeInUp {
        from {
            opacity: 0;
            transform: translateY(30px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }

    @keyframes slideDown {
        from {
            opacity: 0;
            transform: translateY(-50px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }

    @keyframes slideInRight {
        from {
            opacity: 0;
            transform: translateX(50px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }

    @keyframes slideInLeft {
        from {
            opacity: 0;
            transform: translateX(-50px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }

    .stFileUploader > div > div > div {
        text-align: center;
    }

    .success-animation {
        animation: pulse 2s infinite;
    }

    @keyframes pulse {
        0% {
            transform: scale(1);
        }
        50% {
            transform: scale(1.05);
        }
        100% {
            transform: scale(1);
        }
    }
    </style>
    """, unsafe_allow_html=True)

# ================== KHá»I Táº O MODEL VÃ€ CHATBOT ==================
@st.cache_resource
def load_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    try:
        checkpoint = torch.load("./checkpoints/best.pt", map_location=device)
        weights = ViT_B_16_Weights.IMAGENET1K_V1
        model = vit_b_16(weights=weights)
        num_classes = len(os.listdir(r"C:\Users\tam\Documents\data\PlantVillage_Split\test"))
        model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.to(device)
        model.eval()

        transform = weights.transforms()
        class_names = os.listdir(r"C:\Users\tam\Documents\data\PlantVillage_Split\test")

        return model, transform, class_names, device
    except Exception as e:
        st.error(f"âŒ KhÃ´ng thá»ƒ táº£i model: {e}")
        return None, None, None, None

@st.cache_resource
def load_chatbot():
    load_dotenv()

    try:
        loader = TextLoader("books/huong_dan_trong_cay.txt", encoding="utf-8")
        documents = loader.load()

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = splitter.split_documents(documents)
        combined_text = "\n\n".join([chunk.page_content for chunk in chunks])

        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.3,
            google_api_key=os.getenv("GOOGLE_API_KEY")
        )

        return llm, combined_text
    except Exception as e:
        st.error(f"âŒ KhÃ´ng thá»ƒ táº£i chatbot: {e}")
        return None, None

def predict_disease(image, model, transform, class_names, device):
    if model is None:
        return None, 0.0

    try:
        img = image.convert("RGB")
        img_t = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = model(img_t)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]
            pred_idx = np.argmax(probs)

        return class_names[pred_idx], probs[pred_idx]
    except Exception as e:
        st.error(f"âŒ Lá»—i dá»± Ä‘oÃ¡n: {e}")
        return None, 0.0

def chatbot_response(query, context_info, llm, combined_text):
    if llm is None:
        return "âŒ Chatbot chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o."

    try:
        messages = [
            SystemMessage(content="Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» nÃ´ng nghiá»‡p. Tráº£ lá»i thÃ¢n thiá»‡n, dá»… hiá»ƒu cho nÃ´ng dÃ¢n Viá»‡t Nam."),
            HumanMessage(content=f"TÃ i liá»‡u:\n{combined_text}\n\nThÃ´ng tin bá»‡nh cÃ¢y: {context_info}\n\nCÃ¢u há»i: {query}")
        ]
        response = llm.invoke(messages)
        return response.content
    except Exception as e:
        return f"âŒ Lá»—i chatbot: {e}"

# ================== GIAO DIá»†N CHÃNH ==================
def main():
    add_custom_css()

    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸŒ¿ TrÃ­ Tuá»‡ NhÃ¢n Táº¡o NÃ´ng Nghiá»‡p</h1>
        <p>ğŸ¤– Há»‡ thá»‘ng nháº­n diá»‡n bá»‡nh lÃ¡ cÃ¢y & TÆ° váº¥n nÃ´ng nghiá»‡p thÃ´ng minh</p>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.markdown("### ğŸ¯ Chá»n chá»©c nÄƒng")

        page = st.selectbox(
            "ğŸ“± Äiá»u hÆ°á»›ng",
            ["ğŸ  Trang chá»§", "ğŸ”¬ Nháº­n diá»‡n bá»‡nh", "ğŸ’¬ Chatbot tÆ° váº¥n", "ğŸ“Š Thá»‘ng kÃª"]
        )

        st.markdown("---")
        st.markdown("### ğŸŒŸ ThÃ´ng tin")
        st.info("ğŸš€ PhiÃªn báº£n: 2.0\n\nğŸ¯ TÃ¡c giáº£: Nguyá»…n Quang Minh\n\nğŸ’¡ CÃ´ng nghá»‡: PyTorch + Streamlit")

    # Load models
    model, transform, class_names, device = load_model()
    llm, combined_text = load_chatbot()

    # Main content
    if page == "ğŸ  Trang chá»§":
        show_home_page()
    elif page == "ğŸ”¬ Nháº­n diá»‡n bá»‡nh":
        show_disease_detection(model, transform, class_names, device)
    elif page == "ğŸ’¬ Chatbot tÆ° váº¥n":
        show_chatbot(llm, combined_text)
    elif page == "ğŸ“Š Thá»‘ng kÃª":
        show_statistics()

def show_home_page():
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ”¬ Nháº­n diá»‡n bá»‡nh lÃ¡ cÃ¢y</h3>
            <p>Sá»­ dá»¥ng AI Ä‘á»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh lÃ¡ cÃ¢y vÃ  nháº­n diá»‡n cÃ¡c loáº¡i bá»‡nh phá»• biáº¿n vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao.</p>
            <ul>
                <li>âœ… Há»— trá»£ nhiá»u loáº¡i cÃ¢y trá»“ng</li>
                <li>âœ… Äá»™ chÃ­nh xÃ¡c > 90%</li>
                <li>âœ… Káº¿t quáº£ tá»©c thÃ¬</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ“Š Thá»‘ng kÃª chi tiáº¿t</h3>
            <p>Theo dÃµi lá»‹ch sá»­ phÃ¢n tÃ­ch vÃ  xu hÆ°á»›ng bá»‡nh cÃ¢y Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c biá»‡n phÃ¡p phÃ²ng ngá»«a hiá»‡u quáº£.</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ’¬ Chatbot tÆ° váº¥n</h3>
            <p>TrÃ² chuyá»‡n vá»›i AI chuyÃªn gia nÃ´ng nghiá»‡p Ä‘á»ƒ nháº­n tÆ° váº¥n vá»:</p>
            <ul>
                <li>ğŸŒ± Ká»¹ thuáº­t trá»“ng trá»t</li>
                <li>ğŸ› PhÃ²ng chá»‘ng sÃ¢u bá»‡nh</li>
                <li>ğŸ’Š Sá»­ dá»¥ng thuá»‘c báº£o vá»‡ thá»±c váº­t</li>
                <li>ğŸŒ¿ ChÄƒm sÃ³c cÃ¢y trá»“ng</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

        # Metrics
        st.markdown("### ğŸ“ˆ Sá»‘ liá»‡u há»‡ thá»‘ng")
        col1_metric, col2_metric, col3_metric = st.columns(3)

        with col1_metric:
            st.markdown("""
            <div class="metric-card">
                <h2>1,250+</h2>
                <p>LÆ°á»£t phÃ¢n tÃ­ch</p>
            </div>
            """, unsafe_allow_html=True)

        with col2_metric:
            st.markdown("""
            <div class="metric-card">
                <h2>95.8%</h2>
                <p>Äá»™ chÃ­nh xÃ¡c</p>
            </div>
            """, unsafe_allow_html=True)

        with col3_metric:
            st.markdown("""
            <div class="metric-card">
                <h2>24/7</h2>
                <p>Há»— trá»£</p>
            </div>
            """, unsafe_allow_html=True)

def show_disease_detection(model, transform, class_names, device):
    st.markdown("## ğŸ”¬ Nháº­n diá»‡n bá»‡nh lÃ¡ cÃ¢y")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown("""
        <div class="upload-section">
            <h3>ğŸ“¸ Táº£i lÃªn hÃ¬nh áº£nh lÃ¡ cÃ¢y</h3>
            <p>Há»— trá»£ Ä‘á»‹nh dáº¡ng: JPG, JPEG, PNG</p>
        </div>
        """, unsafe_allow_html=True)

# Image input options
        upload_option = st.radio(
            "Chá»n cÃ¡ch táº£i áº£nh:",
            ["ğŸ“¤ Táº£i file", "ğŸ“· Chá»¥p áº£nh"],
            key="disease_upload_option"
        )

        uploaded_file = None
        if upload_option == "ğŸ“¤ Táº£i file":
            uploaded_file = st.file_uploader(
                "Chá»n áº£nh lÃ¡ cÃ¢y",
                type=["jpg", "jpeg", "png"],
                help="Táº£i lÃªn hÃ¬nh áº£nh rÃµ rÃ ng cá»§a lÃ¡ cÃ¢y cáº§n phÃ¢n tÃ­ch"
            )
        else:
            # Camera input
            uploaded_file = st.camera_input("ğŸ“· Chá»¥p áº£nh lÃ¡ cÃ¢y")

        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="ğŸ–¼ï¸ áº¢nh Ä‘Ã£ táº£i lÃªn", use_container_width=True)

            if st.button("ğŸ” PhÃ¢n tÃ­ch ngay", use_container_width=True):
                with st.spinner("ğŸ¤– Äang phÃ¢n tÃ­ch..."):
                    time.sleep(1)  # Animation effect
                    disease, confidence = predict_disease(image, model, transform, class_names, device)

                    if disease:
                        with col2:
                            st.markdown(f"""
                            <div class="feature-card success-animation">
                                <h3>ğŸ¯ Káº¿t quáº£ phÃ¢n tÃ­ch</h3>
                                <h2 style="color: #4CAF50;">ğŸ¦  {disease}</h2>
                                <h3>ğŸ“Š Äá»™ tin cáº­y: {confidence:.1%}</h3>
                            </div>
                            """, unsafe_allow_html=True)

                            # Progress bar for confidence
                            st.progress(float(confidence))

                            if confidence > 0.8:
                                st.success("âœ… Káº¿t quáº£ cÃ³ Ä‘á»™ tin cáº­y cao!")
                            elif confidence > 0.6:
                                st.warning("âš ï¸ Káº¿t quáº£ cÃ³ Ä‘á»™ tin cáº­y trung bÃ¬nh")
                            else:
                                st.error("âŒ Káº¿t quáº£ cÃ³ Ä‘á»™ tin cáº­y tháº¥p, vui lÃ²ng thá»­ áº£nh khÃ¡c")

                            # Store result and image in session state for chatbot
                            st.session_state.disease_info = f"Há»‡ thá»‘ng dá»± Ä‘oÃ¡n lÃ¡ cÃ¢y bá»‹: {disease} (Ä‘á»™ tin cáº­y {confidence:.2f})"
                            st.session_state.analyzed_image = image

    with col2:
        if 'disease_info' not in st.session_state:
            st.markdown("""
            <div class="feature-card">
                <h3>ğŸ’¡ HÆ°á»›ng dáº«n sá»­ dá»¥ng</h3>
                <ol>
                    <li>ğŸ“· Chá»¥p áº£nh lÃ¡ cÃ¢y rÃµ rÃ ng</li>
                    <li>ğŸ“¤ Táº£i áº£nh lÃªn há»‡ thá»‘ng</li>
                    <li>ğŸ” Nháº¥n nÃºt "PhÃ¢n tÃ­ch ngay"</li>
                    <li>ğŸ“‹ Xem káº¿t quáº£ vÃ  Ä‘á»™ tin cáº­y</li>
                    <li>ğŸ’¬ TÆ° váº¥n thÃªm qua Chatbot</li>
                </ol>
            </div>
            """, unsafe_allow_html=True)

def show_chatbot(llm, combined_text):
    st.markdown("## ğŸ’¬ Chatbot tÆ° váº¥n nÃ´ng nghiá»‡p")

    # Show image from disease detection if available
    if 'analyzed_image' in st.session_state and 'disease_info' in st.session_state:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ–¼ï¸ áº¢nh Ä‘Ã£ phÃ¢n tÃ­ch tá»« pháº§n nháº­n diá»‡n bá»‡nh</h3>
        </div>
        """, unsafe_allow_html=True)

        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.image(st.session_state.analyzed_image, caption="ğŸ“¸ áº¢nh lÃ¡ cÃ¢y Ä‘Ã£ phÃ¢n tÃ­ch", use_container_width=True)
            st.info(f"ğŸ” {st.session_state.disease_info}")

    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Chat messages display
    st.markdown("### ğŸ’¬ Cuá»™c trÃ² chuyá»‡n")

    # Create scrollable chat area with better styling
    if st.session_state.messages:
        for i, message in enumerate(st.session_state.messages):
            if message["role"] == "user":
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-end; margin: 10px 0;">
                    <div class="user-message" style="max-width: 80%; margin-left: auto;">
                        ğŸ‘¤ {message["content"]}
                    </div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-start; margin: 10px 0;">
                    <div class="bot-message" style="max-width: 80%; margin-right: auto;">
                        ğŸ¤– {message["content"]}
                    </div>
                </div>
                """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="feature-card" style="text-align: center; margin: 20px 0;">
            <h4>ğŸŒŸ ChÃ o má»«ng Ä‘áº¿n vá»›i Chatbot tÆ° váº¥n nÃ´ng nghiá»‡p!</h4>
            <p>HÃ£y Ä‘áº·t cÃ¢u há»i vá» nÃ´ng nghiá»‡p hoáº·c vá» káº¿t quáº£ phÃ¢n tÃ­ch bá»‡nh lÃ¡ cÃ¢y.</p>
        </div>
        """, unsafe_allow_html=True)

    # Chat input area
    st.markdown("---")

    # Text input and send button
    col_input, col_send = st.columns([4, 1])

    with col_input:
        user_input = st.text_input(
            "ğŸ’¬ Nháº­p cÃ¢u há»i:",
            placeholder="VÃ­ dá»¥: CÃ¡ch phÃ²ng chá»‘ng bá»‡nh Ä‘á»‘m lÃ¡ á»›t?",
            key="chat_input",
            label_visibility="collapsed"
        )

    with col_send:
        send_button = st.button("ğŸ“¤ Gá»­i", use_container_width=True)

    if send_button and user_input:
        # Add user message
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Get context from disease detection if available
        context_info = st.session_state.get('disease_info', "")

        # Get bot response
        with st.spinner("ğŸ¤– Äang suy nghÄ©..."):
            response = chatbot_response(user_input, context_info, llm, combined_text)
            st.session_state.messages.append({"role": "assistant", "content": response})

        st.rerun()

    # Quick suggestions
    st.markdown("### ğŸ’¡ CÃ¢u há»i gá»£i Ã½")

    suggestions = [
        "ğŸŒ± CÃ¡ch trá»“ng vÃ  chÄƒm sÃ³c cÃ¢y á»›t?",
        "ğŸ› PhÃ²ng chá»‘ng sÃ¢u bá»‡nh trÃªn cÃ  chua",
        "ğŸ’Š Thuá»‘c nÃ o tá»‘t cho bá»‡nh Ä‘á»‘m lÃ¡?",
        "ğŸŒ¿ Ká»¹ thuáº­t tÆ°á»›i nÆ°á»›c cho rau xanh"
    ]

    # Display suggestions in 2 columns
    col1, col2 = st.columns(2)
    for i, suggestion in enumerate(suggestions):
        if i % 2 == 0:
            with col1:
                if st.button(suggestion, key=f"suggest_{i}", use_container_width=True):
                    st.session_state.messages.append({"role": "user", "content": suggestion})
                    context_info = st.session_state.get('disease_info', "")
                    response = chatbot_response(suggestion, context_info, llm, combined_text)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.rerun()
        else:
            with col2:
                if st.button(suggestion, key=f"suggest_{i}", use_container_width=True):
                    st.session_state.messages.append({"role": "user", "content": suggestion})
                    context_info = st.session_state.get('disease_info', "")
                    response = chatbot_response(suggestion, context_info, llm, combined_text)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.rerun()

def show_statistics():
    st.markdown("## ğŸ“Š Thá»‘ng kÃª vÃ  BÃ¡o cÃ¡o")

    # Sample data for demonstration
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="ğŸ“ˆ Tá»•ng phÃ¢n tÃ­ch",
            value="1,247",
            delta="23 hÃ´m nay"
        )

    with col2:
        st.metric(
            label="ğŸ¯ Äá»™ chÃ­nh xÃ¡c",
            value="95.8%",
            delta="2.1%"
        )

    with col3:
        st.metric(
            label="ğŸ’¬ CÃ¢u há»i chatbot",
            value="856",
            delta="45 hÃ´m nay"
        )

    with col4:
        st.metric(
            label="ğŸ‘¥ NgÆ°á»i dÃ¹ng",
            value="234",
            delta="12 má»›i"
        )

    # Charts
    st.markdown("### ğŸ“ˆ Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch")

    col1, col2 = st.columns(2)

    with col1:
        # Sample chart data
        chart_data = {
            'NgÃ y': ['T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'CN'],
            'PhÃ¢n tÃ­ch': [23, 45, 56, 78, 32, 67, 89]
        }
        st.bar_chart(chart_data, x='NgÃ y', y='PhÃ¢n tÃ­ch')

    with col2:
        # Disease distribution
        import pandas as pd
        disease_data = pd.DataFrame({
            'Loáº¡i bá»‡nh': ['Bá»‡nh Ä‘á»‘m lÃ¡', 'Bá»‡nh hÃ©o xanh', 'Bá»‡nh thá»‘i rá»…', 'Khá»e máº¡nh'],
            'Sá»‘ lÆ°á»£ng': [35, 28, 22, 15]
        })
        st.bar_chart(disease_data.set_index('Loáº¡i bá»‡nh'))

if __name__ == "__main__":
    main()